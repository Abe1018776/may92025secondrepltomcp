---
description: Multi-role rule file for LangSmith tracing, tagging, and redaction in async RAG pipelines, optimized for Cursor IDE with LangChain transition support.
globs: *.py,openai_service.py
alwaysApply: false
---

### ğŸ” Tracing Requirements  
**ğŸ§  LangSmith Integration Engineer**

- All functions calling OpenAI or handling LLM flow must be wrapped in `@traceable` from `langsmith`.

  > ğŸ’¬ Cursor might suggest:  
  > "This async function calls OpenAI but isnâ€™t traceable. Wrap with `@traceable(name='rag-step-[action]')`."

- Include a clear `name` in each traceable, aligned with the step's intent (`"rag-step-generate"`, `"rag-step-validate"`).

- Traceable steps must include:
  ```python
  @traceable(name="rag-step-[name]", tags=["model:gpt-4o"], metadata={"version": "v1"})
  ```

### ğŸ·ï¸ Tagging & Metadata  
**ğŸ§  LangSmith Engineer + ğŸ“š Educator**

- Always include:
  - `model:<name>`  
  - `purpose:<step>`  
  - `pipeline:<chain>`  

- Metadata should include performance-relevant fields:
  ```python
  metadata={
    "history_len": len(messages),
    "retrieval_time": f"{elapsed:.2f}s",
    "sanitized": True
  }
  ```

  > ğŸ’¬ Cursor might suggest:  
  > "Consider adding `tags` and `metadata` to improve trace filtering and run diagnostics."

### ğŸ” Sanitation & Security  
**ğŸ” Security & Redaction Specialist**

- Never log unfiltered `query`, `user_message`, `history`, or final prompt payloads.  
- Use `utils/sanitization.py` to redact risky content before it reaches `@traceable`.

- Add metadata `"sanitized": True` to indicate trace safety.

  > ğŸ’¬ Cursor might suggest:  
  > "Traced function includes raw user input. Redact or sanitize before logging."

### ğŸ“Š Evaluation Preparation  
**ğŸ§  LangSmith Engineer + ğŸ” RAG Engineer**

- If `run_on_dataset()` is added:
  - Use `reference_example_id` to link to examples
  - Add evaluator metadata such as:
    ```python
    metadata={"eval_target": "answer", "metric": "faithfulness"}
    ```

- Version datasets semantically (`qa-v1`, `qa-r3-userstudy`) or with commit SHA

  > ğŸ’¬ Cursor might suggest:  
  > "Consider tagging eval runs with `eval:faithfulness` and linking to examples with `reference_example_id`."

### â­ï¸ LangChain / LangGraph Forward Compatibility  
**ğŸ”— LangChain Architect + ğŸ“š Educator**

- Use `.with_config({"tags": [...], "metadata": {...}})` on LangChain `Runnable` objects:
  ```python
  chain = retrieval.with_config(tags=["retriever"], metadata={"name": "rag-step-retrieve"})
  ```

- LangGraph nodes should define `name`, `tags`, and store `parent_run_id` for tracing continuity.

  > ğŸ’¬ Cursor might suggest:  
  > "This Runnable step should be tagged and given traceable metadata for LangSmith observability."

### ğŸ§  IDE Instruction & Developer Experience  
**ğŸ“š AI Developer Educator**

- Cursor should not only flag problems, but explain why.  
- All prompts must:
  - Use a helpful, non-punitive tone
  - Teach developers about long-term LLM observability practices
  - Highlight how rules prevent invisible bugs or compliance issues

  > ğŸ’¬ Cursor might suggest:  
  > "Tracing isnâ€™t just for debuggingâ€”it powers reproducible prompt tuning and user trust."

### ğŸ§© Developer Workflow Integration  
**ğŸ§© Cursor IDE Rule Designer**

- Rules trigger IDE suggestions when:
  - LLM-using functions arenâ€™t wrapped in `@traceable`
  - Tags like `model:` or `purpose:` are missing
  - Raw input appears inside a traced step
  - No metadata is present in a `@traceable` block

- Designed to be both linting and educational.  
- Updates to this file should be treated like code changes â€” peer reviewed and versioned.

### ğŸ§° Example Output (For Developers)

```python
@traceable(
    name="rag-step-openai-generate",
    tags=["model:gpt-4o", "purpose:generate", "pipeline:validate-generate"],
    metadata={
        "retrieval_time": "1.12s",
        "sanitized": True
    }
)
async def run_openai_generation_step(...):
    ...
```